\chapter{Discussões}
\label{chp:discussions}

A seguir serão apresentadas discussões sobre os resultados apresentados no capítulo \ref{chp:results}, bem como limitações do sistema proposto neste estudo, e trabalhos futuros na área de busca de código-fonte por linguagem natural. Por fim, serão relacionadas as contribuições do presente estudo.

No experimento 1, houveram amostras onde todas as palavras retiradas geraram praticamente o mesmo valor de acurácia, ou ainda amostras onde a redução de acurácia aconteceu em stop-words ou outras palavras não tão relevantes para aquele comentário em questão. Com isso, tendo em mente que a entrada do modelo de comparação são dois \textit{embeddings} com tamanho 768, e gerados por redes \textit{transformers} complexas, é possível que o modelo de comparação, o qual é propositalmente mais simples que os geradores de \textit{embeddings} utilizados, não tenha conseguido generalizar todas informações semânticas contidas nos embeddings de entrada.

Entretando, os resultados do experimento 1 também mostraram que, para parte das amostras, a retirada de palavras importantes do comentário reduziu notavelmente a acurácia do modelo, o que indica que a rede conseguiu captar o significado semântico destas palavras retiradas no comentário original. Algumas amostras, porém, obtiveram diferenças de acurácia menores do que outras. Essa diferença menor de acurácia entre amostras também pode ser explicada, já que apesar de uma palavra importante estar sendo removida do comentário, o \textit{embedding} de código-fonte será idêntico para todas as queries $C^-$ geradas para essa amostra, o que significa que ao menos 50\% da entrada do modelo de comparação será igual, mesmo com a query $C^-$ gerada. Portanto, diferenças substanciais da similaridade, apenas removendo uma palavra do comentário original, mostra o potencial do modelo de comparação proposto neste estudo.

No experimento 2, ao invés de comparar a similiaridade com os dados da mesma amostra que $C^-$ foi gerado, as queries $C^-$ foram aplicadas no contexto de busca de código-fonte. Neste contexto, dado um termo de busca em linguagem natural (também chamado de \textit{query}), o resultado da busca é uma lista de possíveis trechos de código-fonte, ordenados por similaridade em ordem decrescente. Todos os trechos de código-fonte utilizados na busca também foram utilizados durante o treinamento do modelo de comparação.

Os valores obtidos nas métricas \gls{mrr} e \textit{SuccessRate@k} foram baixos quando comparados diretamente com outros estudos presentes na literatura. \textcite{Gu2018DeepCS}, por exemplo, obteve $0.367$ e $0.465$ nas métricas \textit{SuccessRate@1} e \gls{mrr}, respectivamente, enquanto \textcite{Gu2021CRaDLeDC} obteve $0.791$ e $0.843$ nas mesmas métricas, respectivamente. Entretanto, não é possível comparar diretamente tais resultados, já que os experimentos feitos no presente estudo diferem dos experimentos realizados pelos trabalhos citados.

Para este experimento, utilizou-se a métrica de recuperação de informação chamada de \textit{SuccessRate@k} e os valores 1, 5 e 10 para $k$. Conforme os resultados apresentados na seção \ref{sec:experiments:experiment-2}, tem-se que as buscam feitas com $k=10$ obtiveram os melhores resultados, diminuindo a acurácia para $k=5$ e $k=1$. Além disso, nota-se que, para $k=10$, a curva converge mais rápido para 1. Entretanto, mesmo que as curvas de $k=5$ e $k=1$ sejam parecidas com $k=10$, nota-se que não houveram muitas amostras com valores altos de \textit{SuccessRate@k} para $k=1$ e $k=5$. Além disso, é esperado que para $k=10$ o valor de \textit{SuccessRate@k} seja maior que $k=5$ ou $k=1$, já que há mais chances do resultado esperado estar nas 10 primeiras posições do que nas 5 primeiras, por exemplo.

Por fim, o experimento 3 foi feito utilizando queries e valores de relevância disponíveis na base de dados \textit{CodeSearchNet}, conforme descrito na seção \ref{sec:experiments:experiment-3}. Aqui, utilizou-se tanto as queries disponíveis na base em questão, como suas respectivas relevâncias em relação a determinado trecho de código-fonte, disponíveis na mesma base. Além disso, muitos trechos de código-fonte dessa base de queries não foram utilizados nos experimentos 1 e 2. Por conta desses fatores, não foi possível utilizar métricas de recuperação de informação como \textit{Hit@k}. Com isso, para este experimento, foi utilizado a similaridade (resultante do modelo de comparação) e o valor de relevância para determinar se o resultado do modelo de comparação está correto ou não.

\section{Limitações e trabalhos futuros}
\label{sec:discussions:future-works}

Durante o desenvolvimento deste trabalho, foram encontradas limitações em relação ao sistema proposto. Uma das limitações foi o tamanho dos embeddings gerados, tanto para comentário quanto para código-fonte. Durante o desenvolvimento do sistema em questão, foram utilizados modelos de embeddings que geram embeddings do mesmo tamanho, a saber, 768. Neste caso, caso o tamanho da entrada desses modelos seja maior do que 768, o vetor resultante será truncado; caso contrário, será adicionado zeros no final deste embedding para atingir o tamanho desejado. Portanto, apesar de quaisquer modelos de embedding poderem ser usados no sistema proposto, o modelo de comparação espera embeddings de tamanho 768, tanto para comentário quanto para código-fonte. 

Outra limitação é a topologia utilizada no modelo de comparação. Propositalmente, o modelo de comparação utilizou uma rede \gls{mlp}, a qual é mais simples tanto em relação à outras redes neurais (como \gls{lstm}, por exemplo), quanto em relação aos modelos de embedding utilizados neste trabalho, os quais são baseados em redes \textit{transformers}. Foram dois motivos que levaram a utilização de uma topologia mais simples para o modelo de comparação: o primeiro foi os requisitos computacionais. Redes \gls{mlp}, por serem mais simples, requerem muito menos recursos computacionais para treinamento do que uma rede baseada em \textit{transformer}, por exemplo. O segundo motivo foi justamente analisar como uma topologia mais simples se comportaria com entradas geradas por modelos mais complexos.

Diante disso, uma recomendação para trabalhos futuros seria utilizar outras topologias para comparação de embeddings. Antes dos modelos \textit{transformers} serem o estado da arte na área de \gls{nlp}, esse posto era ocupado pelas redes recorrentes como \gls{lstm}, por exemplo. Portanto, seria interessante validar se tais redes, apesar de mais complexas e, portanto, demandarem mais recursos computacionais que o modelo de comparação proposto no presente estudo, podem generalizar melhor as informações contidas nos \textit{embeddings} e, com isso, gerarem melhores resultados na busca de código-fonte a partir de linguagem natural.

Além disso, no presente estudo utilizou-se apenas uma combinação de modelos de embeddings para comentário e código-fonte. Em trabalhos futuros, pode-se utilizar outros modelos de embedding, tanto para linguagem natural (comentário) quanto para código-fonte. Inclusive, tais modelos de embedding não precisam, necessariamente, serem baseados em transformers, embora hoje esses sejam o estado da arte. Modelos de embedding como \gls{nbow}, por exemplo, também podem ser utilizados no sistema em questão.

Ainda, cita-se também a possibilidade de, em trabalhos futuros, de ajustar os parâmetros da rede \gls{mlp} utilizada para o atual modelo de comparação, a fim de melhorar a performance do sistema. Parâmetros como número e tipo de camadas intermediárias, tamanho dos embeddings de entrada e funções de ativação (tanto das camadas intermediárias quanto da camada de saída), podem facilmente ser alterados a fim de aperfeiçoar o sistema proposto. Além disso, os resultados do experimento 1 apontam que quanto maior o tamanaho do comentário, menor a eficácia da rede em determinar palavras semanticamente relevantes, embora essa regra não se aplique a todas as amostras utilizadas. Com isso, a remoção de palavras não relevantes (\textit{stop words}) durante o treinamento do modelo de comparação pode também melhorar sua performance.

Outra possibilidade para trabalhos futuros seria utilizar redes mais complexas para o modelo de comparação. Como redes recorrentes eram o estado da arte antes do advento dos modelos \textit{transformers}, substituir a atual rede \gls{mlp} por uma outra topologia como \gls{lstm} pode melhorar os resultados obtidos no presente estudo.

Por fim, os resultados obtidos na presente pesquisa foram submetidos à revista Journal of Systems and Software.