\chapter{CONCLUSÃO}
\label{chp:conclusao}

A busca de código-fonte a partir de linguagem natural é uma tarefa essencial para engenheiros de \textit{software} nas mais diversas áreas da indústria \cite{Sadowski2015HowDS}. Como visto no capítulo \ref{chp:relatedWorks}, inúmeros trabalhos relacionados à busca de código-fonte tem sido publicados nos últimos anos. 

Atualmente, os modelos \textit{transformers} são os mais utilizados no problema de busca de código-fonte, devido, principalmente, à sua capacidade de extrair informações semânticas dos dados de entrada, como \textit{queries} em linguagem natural para busca de código-fonte. Diversos modelos \textit{transformers} pré treinados estão disponíveis atualmente. Porém, para adaptar tais modelos para dado problema específico, estes demandam consideráveis quantidades de recursos computacionais, tanto para serem treinados novamente quanto para o \textit{fine tuning}. 

Diante disso, o presente trabalho implementou um sistema de busca de código-fonte a partir de linguagem natural, utilizando uma rede \gls{mlp} para determinar a similaridade entre dois \textit{embeddings}, gerados por dois modelos \textit{transformers} pré treinados: um em linguagem natural, e outro em linguagem de programação. O modelo de comparacão, o qual consiste em uma rede \gls{mlp}, foi treinado com pares de \textit{embeddings} código-fonte/comentário, a fim de determinar o grau de similaridade entre um texto escrito em linguagem natural (\textit{query}) e um trecho de código-fonte.

Implementou-se três experimentos para avaliar a performance do sistema proposto. Dos resultados, analisando 100 pares código-fonte/comentário da base de treinamento, obteve-se $0.130$ de média de \gls{mrr}, além das médias $0.044$, $0.176$, $0.297$ para os valores de $k=1$, $k=5$ e $k=10$ da métrica \textit{SuccessRate@k}. Embora o modelo não tenha obtido uma média de resultados expressiva, dois pontos são importantes de serem mencionados. O primeiro é que não é possível realizar uma comparação direta desses valores obtidos no presente estudo com resultados de trabalhos como \textcite{Gu2018DeepCS} ou \textcite{Gu2021CRaDLeDC}, já que os experimentos conduzidos nestes trabalhos foram diferentes dos realizados no presente trabalho. Segundo, que apesar da média obtida ter sido baixa, o modelo obteve bons resultados para alguns pares testados, tanto no experimento de generalização quanto nos de busca, o que indica que trabalhos futuros podem ser realizados a partir deste, a fim de melhorar a performance geral do modelo de comparação.
